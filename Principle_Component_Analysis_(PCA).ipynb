{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "yIccLPcXccD5",
    "outputId": "684acf0b-02ca-4470-99dc-564355dd2cef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# import some data to play with. We are loading the popular Iris Data set\n",
    "irisdata = sns.load_dataset('iris')\n",
    "irisdata.head()  # have a look at the attributres(=> X) and Labels(=> y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUUiElQ6ccEE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.86585863  0.66072644 -0.0168809  -0.20120114]\n",
      " [ 1.3548494   0.40179469  0.19810987  0.20592094]\n",
      " [-2.38483191 -0.45175726  0.20057524  0.04728643]\n",
      " [ 0.89710379  0.21504664 -0.46176653 -0.10044891]\n",
      " [ 2.04539715  0.90342091  0.22746313 -0.17786793]]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "X = irisdata.drop('species', axis=1)  \n",
    "y = irisdata['species']\n",
    "\n",
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n",
    "\n",
    "#  PCA performs best with a normalized feature set. \n",
    "#  We will perform standard scalar normalization to normalize our feature set.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Performing PCA using Scikit-Learn is a two-step process:\n",
    "# 1. Initialize the PCA class by passing the number of components to the constructor.\n",
    "# 2. Call the fit and then transform method by passing the feature set to these methods. \n",
    "#    The transform method returns the specified number of principal components.\n",
    "\n",
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()  \n",
    "X_train = pca.fit_transform(X_train)  \n",
    "X_test = pca.transform(X_test)  \n",
    "\n",
    "\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M9lmowEkccEM",
    "outputId": "9854cbae-2dbc-4870-f975-ba272ea31caf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73838804, 0.22318067, 0.03408865, 0.00434264])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance = pca.explained_variance_ratio_ \n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyGqS5kKccEU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01197422]\n",
      " [ 0.29176303]\n",
      " [ 1.27693979]\n",
      " [-2.25154785]\n",
      " [-2.15421304]]\n"
     ]
    }
   ],
   "source": [
    "# Let's first try to use 1 principal component to train our algorithm. \n",
    "# To do so, execute the following code:\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state=100)\n",
    "\n",
    "#  PCA performs best with a normalized feature set. \n",
    "#  We will perform standard scalar normalization to normalize our feature set.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1)  \n",
    "X_train = pca.fit_transform(X_train)  \n",
    "X_test = pca.transform(X_test)  \n",
    "\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "WnmjbfCcccEa",
    "outputId": "0211f450-dba6-4472-c601-4b8266da2b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0  5  1]\n",
      " [ 0  1 12]]\n",
      "Accuracy  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Training and Making Predictions\n",
    "# In this case we'll use random forest classification \n",
    "# for making the predictions.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0, \n",
    "                                    n_estimators=10)  \n",
    "classifier.fit(X_train, y_train)\n",
    "# Please Note : if n_estimators is not specified in RandomForestClassifier\n",
    "# default value of 10 is taken. For this you may get FutureWarning\n",
    "# To avoid the warning, either specify n_estimators or suppress warnings\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)  \n",
    "\n",
    "\n",
    "# Performance Evaluation\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print('Accuracy ' ,  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8J0JCxh-ccEh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.87728863e+00 -1.97725225e-01]\n",
      " [-2.32463091e+00  2.28963933e-01]\n",
      " [ 3.43464467e+00 -1.29167636e-03]\n",
      " [-2.16262897e+00  2.79560533e+00]\n",
      " [ 1.39650638e+00 -4.73982558e-01]]\n",
      "[[11  0  0]\n",
      " [ 0  4  2]\n",
      " [ 0  5  8]]\n",
      "Accuracy  0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Try PCA with 2 Principal Components\n",
    "# pca = PCA(n_components=2)\n",
    "#------------------------------------------\n",
    "# all the above steps would have to be repeated.\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state=100)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca=PCA(n_components=2)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "\n",
    "print(X_test[:5])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0, \n",
    "                                    n_estimators=10)  \n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print('Accuracy ' ,  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dRjNLqy1X-o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.87728863e+00 -1.97725225e-01  2.18513954e-01]\n",
      " [-2.32463091e+00  2.28963933e-01  9.86858462e-02]\n",
      " [ 3.43464467e+00 -1.29167636e-03 -7.99173028e-01]\n",
      " [-2.16262897e+00  2.79560533e+00  6.51532670e-02]\n",
      " [ 1.39650638e+00 -4.73982558e-01 -6.22294960e-02]]\n",
      "[[11  0  0]\n",
      " [ 0  6  0]\n",
      " [ 0  9  4]]\n",
      "Accuracy  0.7\n"
     ]
    }
   ],
   "source": [
    "# Try PCA with 3 Principal Components\n",
    "# pca = PCA(n_components=3)\n",
    "#------------------------------------------\n",
    "# all the above steps would have to be repeated.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=100)\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=3)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "\n",
    "print(X_test[:5])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0, \n",
    "                                    n_estimators=10)  \n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print('Accuracy ' ,  accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "10_Principle Component Analysis_(PCA)_Unsupervised_ML Algo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
